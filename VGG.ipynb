{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GDDOTqP5109C"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cv2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-61183902b158>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'cv2'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from random import randint\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEIz3jMa16M5",
    "outputId": "a9a2f6bd-1783-4775-9a6f-3991a50d74a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EWSDI_591-lU"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"./images_l.pkl\")\n",
    "label_df = pd.read_pickle(\"./labels_l.pkl\")\n",
    "test_df = pd.read_pickle(\"./images_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-Yz-6YZ2I35"
   },
   "outputs": [],
   "source": [
    "cut = int(30000 * 0.9)\n",
    "image_train_base = train_df[:cut]\n",
    "label_train_base = label_df[:cut]\n",
    "\n",
    "image_val_base = train_df[cut:]\n",
    "label_val_base = label_df[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xnjJ6QWY2KHV"
   },
   "outputs": [],
   "source": [
    "image_train = np.append(image_train_base, image_train_base, axis=0)\n",
    "label_train = np.append(label_train_base, label_train_base, axis=0)\n",
    "\n",
    "image_val = np.append(image_val_base, image_val_base, axis=0)\n",
    "label_val = np.append(label_val_base, label_val_base, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "N_HPqz892MzJ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9H6L8g1n2PbL"
   },
   "outputs": [],
   "source": [
    "def denoise(src):\n",
    "  blur_data = cv2.GaussianBlur(src, (3, 1), 0)\n",
    "  retval, denoised_data = cv2.threshold(blur_data, 85, maxval=255, type=cv2.THRESH_TOZERO)\n",
    "\n",
    "  return denoised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ufIePeah2R0l"
   },
   "outputs": [],
   "source": [
    "image_train = denoise(image_train)\n",
    "image_val = denoise(image_val)\n",
    "test_df = denoise(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OQTth0V82UYv"
   },
   "outputs": [],
   "source": [
    "class Transform_Dataset(Dataset):\n",
    "  def __init__(self, X, \n",
    "               transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize(224),\n",
    "                  transforms.ToTensor(), transforms.Normalize(mean=(0.0,), std=(1.0,))])):\n",
    "  \n",
    "    self.X = X.astype(np.uint8)[:,:,:,None]\n",
    "    # self.X = X\n",
    "    self.transform = transform\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.transform(self.X[idx]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VOcQvEkt2W1P"
   },
   "outputs": [],
   "source": [
    "RandAffine = transforms.RandomAffine(degrees=25, translate=(0, 0), scale=(1.0, 1.0))\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "  transforms.ToPILImage(),\n",
    "  transforms.Resize(224),\n",
    "  RandAffine.to(device),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=(0.5,), std=(0.5,)).to(device)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ra4SP1aV2ZN0"
   },
   "outputs": [],
   "source": [
    "#改改变量名字\n",
    "train_dataset = Transform_Dataset(image_train, train_transform)\n",
    "images_l_loader = DataLoader(dataset=train_dataset, batch_size=30, shuffle=False)\n",
    "\n",
    "val_dataset = Transform_Dataset(image_val, train_transform)\n",
    "images_val_loader = DataLoader(dataset=val_dataset, batch_size=30, shuffle=False)\n",
    "\n",
    "labels_l_loader = DataLoader(dataset=label_train, batch_size=30, shuffle=False)\n",
    "\n",
    "test_dataset = Transform_Dataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=30, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UL30Iu-_2bmD"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oQSb8iN32eSr"
   },
   "outputs": [],
   "source": [
    "#这里也可以改成你自己的\n",
    "def predict(model, data_loader):\n",
    "  total_output = []\n",
    "  for i, data in enumerate(data_loader):\n",
    "    if torch.cuda.is_available():\n",
    "      output = model(data).cpu().detach().numpy()\n",
    "    else:\n",
    "      output = model(data).detach().numpy()\n",
    "    # print(output.shape)\n",
    "\n",
    "    for row_output in output:\n",
    "      # print(row_output.shape)\n",
    "      # find the max two number\n",
    "      max1 = np.max(row_output[:10])\n",
    "      # print(output_without_max1.shape)\n",
    "      max2 = np.max(row_output[10:])\n",
    "      # print(\"max1 = \", max1)\n",
    "      # print(\"max2 = \", max2)\n",
    "      # find index of max1 and max2\n",
    "      max1_index = np.where(row_output == max1)\n",
    "      max2_index = np.where(row_output == max2)\n",
    "      # print(max1_index)\n",
    "      # print(max2_index)\n",
    "      row_output = np.zeros(row_output.shape, dtype=int)\n",
    "\n",
    "      row_output[max1_index[0][0]] = 1\n",
    "      row_output[max2_index[0][0]] = 1\n",
    "\n",
    "      # print(np.where(row_output == 1))\n",
    "      total_output.append(row_output)\n",
    "    \n",
    "  return np.array(total_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "E-Zc9NCl2gaU"
   },
   "outputs": [],
   "source": [
    "#这里可以改成你自己的\n",
    "def accuracy(images_val_loader, labels_val, model):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  output = predict(model,images_val_loader)\n",
    "  i = 0\n",
    "  labels = labels_val.astype(int)\n",
    "  while i < len(output):\n",
    "    #print(output[i])\n",
    "    #print(labels[i])\n",
    "    if (output[i] == labels[i]).all():\n",
    "      correct += 1\n",
    "    total += 1\n",
    "    i += 1\n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ao4o1o_92i1X"
   },
   "outputs": [],
   "source": [
    "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "                512, 512, 512, 512, 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "izNqPdcg2oJM"
   },
   "outputs": [],
   "source": [
    "def get_vgg_layers(config, batch_norm):\n",
    "    \n",
    "    layers = []\n",
    "    in_channels = 1\n",
    "    \n",
    "    for c in config:\n",
    "        assert c == 'M' or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size = 2).to(device)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size = 3, padding = 1).to(device)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c).to(device), nn.ReLU(inplace = True).to(device)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace = True).to(device)]\n",
    "            in_channels = c\n",
    "            \n",
    "    return nn.Sequential(*layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vC2xinBu2qEM"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = features\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7).to(device)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096).to(device),\n",
    "            nn.ReLU(inplace = True).to(device),\n",
    "            nn.Dropout(0.5).to(device),\n",
    "            nn.Linear(4096, 4096).to(device),\n",
    "            nn.ReLU(inplace = True).to(device),\n",
    "            nn.Dropout(0.5).to(device),\n",
    "            nn.Linear(4096, output_dim).to(device),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zPXjovMr2sQD"
   },
   "outputs": [],
   "source": [
    "vgg19_layers_bn = get_vgg_layers(vgg19_config, batch_norm = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HvvXb5rK2uFj"
   },
   "outputs": [],
   "source": [
    "def train_vgg(model, epoches, image_train_loader, label_train_loader, image_val_loader, label_val):\n",
    "\n",
    "  optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "  scheduler = lr_scheduler.StepLR(optimizer,step_size = 10, gamma = 0.5)\n",
    "\n",
    "  for epoch in range(epoches):\n",
    "    image_train_dl_iterator = iter(image_train_loader)\n",
    "\n",
    "    for i, label in enumerate(label_train_loader, 0):\n",
    "      inputs = next(image_train_dl_iterator).to(device)\n",
    "      inputs = inputs.float().to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(inputs).to(device)\n",
    "\n",
    "      loss = criterion(outputs, label.to(device)).to(device)\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    val_accuracy = accuracy(image_val_loader, label_val, model)\n",
    "    #这一行可以改成你自己的\n",
    "    print('[%d] loss: %.3f  val_accuracy: %.4f' % (epoch + 1, loss.item(), val_accuracy))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0r5oN4sS2yD7"
   },
   "outputs": [],
   "source": [
    "VGG19_bn = VGG(vgg19_layers_bn, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqjDw7bs2zxq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] loss: 3.562  val_accuracy: 0.5008\n",
      "[2] loss: 2.526  val_accuracy: 0.8057\n",
      "[3] loss: 2.409  val_accuracy: 0.8696\n",
      "[4] loss: 1.942  val_accuracy: 0.8958\n",
      "[5] loss: 1.775  val_accuracy: 0.9064\n",
      "[6] loss: 1.635  val_accuracy: 0.9252\n",
      "[7] loss: 1.579  val_accuracy: 0.9286\n",
      "[8] loss: 1.706  val_accuracy: 0.9304\n",
      "[9] loss: 1.519  val_accuracy: 0.9308\n",
      "[10] loss: 1.465  val_accuracy: 0.9397\n",
      "[11] loss: 1.502  val_accuracy: 0.9461\n",
      "[12] loss: 1.420  val_accuracy: 0.9493\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17976/3800054872.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel_vgg19_bn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_vgg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mVGG19_bn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_l_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels_l_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimages_val_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17976/3941231193.py\u001b[0m in \u001b[0;36mtrain_vgg\u001b[1;34m(model, epoches, image_train_loader, label_train_loader, image_val_loader, label_val)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabel_train_loader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_train_dl_iterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m       \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    520\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 521\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    522\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    523\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    559\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 561\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    562\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    563\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\master\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_17976/3262753233.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_vgg19_bn = train_vgg(VGG19_bn, 20, images_l_loader, labels_l_loader, images_val_loader, label_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrKHdkzn231l"
   },
   "outputs": [],
   "source": [
    "#这个地方可以改成你自己的\n",
    "test_predictions = predict(VGG16_bn, test_loader)\n",
    "d = {'Id' : [x for x in range(0, len(test_predictions))], 'Category' : [''.join([str(i) for i in x]) for x in test_predictions.tolist()]}\n",
    "submission = pd.DataFrame(d)\n",
    "submission.rename(columns={'Id':'# Id'}, inplace=True)\n",
    "print(submission.shape)\n",
    "submission.to_csv(path_or_buf='submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "VGG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
