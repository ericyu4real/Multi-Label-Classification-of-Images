{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GDDOTqP5109C"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import lr_scheduler \n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from random import randint\n",
    "from torch.utils.data import Dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rEIz3jMa16M5",
    "outputId": "a9a2f6bd-1783-4775-9a6f-3991a50d74a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Preparing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "EWSDI_591-lU"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_pickle(\"images_l.pkl\")\n",
    "label_df = pd.read_pickle(\"labels_l.pkl\")\n",
    "test_df = pd.read_pickle(\"images_test.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "z-Yz-6YZ2I35"
   },
   "outputs": [],
   "source": [
    "cut = int(30000 * 0.9)\n",
    "image_train_base = train_df[:cut]\n",
    "label_train_base = label_df[:cut]\n",
    "\n",
    "image_val_base = train_df[cut:]\n",
    "label_val_base = label_df[cut:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "xnjJ6QWY2KHV"
   },
   "outputs": [],
   "source": [
    "image_train = np.append(image_train_base, image_train_base, axis=0)\n",
    "label_train = np.append(label_train_base, label_train_base, axis=0)\n",
    "\n",
    "image_val = np.append(image_val_base, image_val_base, axis=0)\n",
    "label_val = np.append(label_val_base, label_val_base, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "9H6L8g1n2PbL"
   },
   "outputs": [],
   "source": [
    "def denoise(src):\n",
    "  blur_data = cv2.GaussianBlur(src, (3, 1), 0)\n",
    "  retval, denoised_data = cv2.threshold(blur_data, 85, maxval=255, type=cv2.THRESH_TOZERO)\n",
    "\n",
    "  return denoised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ufIePeah2R0l"
   },
   "outputs": [],
   "source": [
    "image_train = denoise(image_train)\n",
    "image_val = denoise(image_val)\n",
    "test_df = denoise(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "OQTth0V82UYv"
   },
   "outputs": [],
   "source": [
    "class Transform_Dataset(Dataset):\n",
    "  def __init__(self, X, \n",
    "               transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize(224),\n",
    "                  transforms.ToTensor(), transforms.Normalize(mean=(0.0,), std=(1.0,))])):\n",
    "  \n",
    "    self.X = X.astype(np.uint8)[:,:,:,None]\n",
    "    # self.X = X\n",
    "    self.transform = transform\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.transform(self.X[idx]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "VOcQvEkt2W1P"
   },
   "outputs": [],
   "source": [
    "RandAffine = transforms.RandomAffine(degrees=25, translate=(0, 0), scale=(1.0, 1.0))\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "  transforms.ToPILImage(),\n",
    "  transforms.Resize(224),\n",
    "  RandAffine.to(device),\n",
    "  transforms.ToTensor(),\n",
    "  transforms.Normalize(mean=(0.5,), std=(0.5,)).to(device)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ra4SP1aV2ZN0"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = Transform_Dataset(image_train, train_transform)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=30, shuffle=False)\n",
    "\n",
    "val_dataset = Transform_Dataset(image_val, train_transform)\n",
    "validation_loader = DataLoader(dataset=val_dataset, batch_size=30, shuffle=False)\n",
    "\n",
    "train_label_loader = DataLoader(dataset=label_train, batch_size=30, shuffle=False)\n",
    "\n",
    "test_dataset = Transform_Dataset(test_df)\n",
    "test_loader = DataLoader(test_dataset, batch_size=30, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "UL30Iu-_2bmD"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss().to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer, and Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oQSb8iN32eSr"
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(model, data_loader):\n",
    "  total_output = []\n",
    "  for i, data in enumerate(data_loader):\n",
    "    if torch.cuda.is_available():\n",
    "      output = model(data).cpu().detach().numpy()\n",
    "    else:\n",
    "      output = model(data).detach().numpy()\n",
    "    # print(output.shape)\n",
    "\n",
    "    for row_output in output:\n",
    "      # print(row_output.shape)\n",
    "      # find the max two number\n",
    "      max1 = np.max(row_output[:10])\n",
    "      # print(output_without_max1.shape)\n",
    "      max2 = np.max(row_output[10:])\n",
    "      # print(\"max1 = \", max1)\n",
    "      # print(\"max2 = \", max2)\n",
    "      # find index of max1 and max2\n",
    "      max1_index = np.where(row_output == max1)\n",
    "      max2_index = np.where(row_output == max2)\n",
    "      # print(max1_index)\n",
    "      # print(max2_index)\n",
    "      row_output = np.zeros(row_output.shape, dtype=int)\n",
    "\n",
    "      row_output[max1_index[0][0]] = 1\n",
    "      row_output[max2_index[0][0]] = 1\n",
    "\n",
    "      # print(np.where(row_output == 1))\n",
    "      total_output.append(row_output)\n",
    "    \n",
    "  return np.array(total_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "E-Zc9NCl2gaU"
   },
   "outputs": [],
   "source": [
    "\n",
    "def accuracy(images_val_loader, labels_val, model):\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  output = predict(model,images_val_loader)\n",
    "  i = 0\n",
    "  labels = labels_val.astype(int)\n",
    "  while i < len(output):\n",
    "    #print(output[i])\n",
    "    #print(labels[i])\n",
    "    if (output[i] == labels[i]).all():\n",
    "      correct += 1\n",
    "    total += 1\n",
    "    i += 1\n",
    "  return correct/total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VGG Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ao4o1o_92i1X"
   },
   "outputs": [],
   "source": [
    "vgg19_config = [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', \n",
    "                512, 512, 512, 512, 'M']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "izNqPdcg2oJM"
   },
   "outputs": [],
   "source": [
    "def get_vgg_layers(config, batch_norm):\n",
    "    \n",
    "    layers = []\n",
    "    in_channels = 1\n",
    "    \n",
    "    for c in config:\n",
    "        assert c == 'M' or isinstance(c, int)\n",
    "        if c == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size = 2).to(device)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, c, kernel_size = 3, padding = 1).to(device)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(c).to(device), nn.ReLU(inplace = True).to(device)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace = True).to(device)]\n",
    "            in_channels = c\n",
    "            \n",
    "    return nn.Sequential(*layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vC2xinBu2qEM"
   },
   "outputs": [],
   "source": [
    "class VGG(nn.Module):\n",
    "    def __init__(self, features, output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.features = features\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(7).to(device)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 4096).to(device),\n",
    "            nn.ReLU(inplace = True).to(device),\n",
    "            nn.Dropout(0.5).to(device),\n",
    "            nn.Linear(4096, 4096).to(device),\n",
    "            nn.ReLU(inplace = True).to(device),\n",
    "            nn.Dropout(0.5).to(device),\n",
    "            nn.Linear(4096, output_dim).to(device),\n",
    "        ).to(device)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        h = x.view(x.shape[0], -1)\n",
    "        x = self.classifier(h)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "zPXjovMr2sQD"
   },
   "outputs": [],
   "source": [
    "vgg19_layers_bn = get_vgg_layers(vgg19_config, batch_norm = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "HvvXb5rK2uFj"
   },
   "outputs": [],
   "source": [
    "def train_vgg(model, epoches, image_train_loader, label_train_loader, image_val_loader, label_val):\n",
    "\n",
    "  optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.9)\n",
    "  scheduler = lr_scheduler.StepLR(optimizer,step_size = 10, gamma = 0.5)\n",
    "\n",
    "  for epoch in range(epoches):\n",
    "    image_train_dl_iterator = iter(image_train_loader)\n",
    "\n",
    "    for i, label in enumerate(label_train_loader, 0):\n",
    "      inputs = next(image_train_dl_iterator).to(device)\n",
    "      inputs = inputs.float().to(device)\n",
    "\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      outputs = model(inputs).to(device)\n",
    "\n",
    "      loss = criterion(outputs, label.to(device)).to(device)\n",
    "      loss.backward()\n",
    "\n",
    "      optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    val_accuracy = accuracy(image_val_loader, label_val, model)\n",
    "\n",
    "    print('[%d] loss: %.3f  val_accuracy: %.4f' % (epoch + 1, loss.item(), val_accuracy))\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0r5oN4sS2yD7"
   },
   "outputs": [],
   "source": [
    "VGG19_bn = VGG(vgg19_layers_bn, 36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PqjDw7bs2zxq"
   },
   "outputs": [],
   "source": [
    "model_vgg19_bn = train_vgg(VGG19_bn, 20, train_loader, train_label_loader, validation_loader, label_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hrKHdkzn231l"
   },
   "outputs": [],
   "source": [
    "test_predictions = predict(VGG19_bn, test_loader)\n",
    "d = {'Id' : [x for x in range(0, len(test_predictions))], 'Category' : [''.join([str(i) for i in x]) for x in test_predictions.tolist()]}\n",
    "submission = pd.DataFrame(d)\n",
    "submission.rename(columns={'Id':'# Id'}, inplace=True)\n",
    "print(submission.shape)\n",
    "submission.to_csv(path_or_buf='submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "VGG.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
